{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekhZPOokhdiX"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-etEZ3dVhez6"
   },
   "source": [
    "Graded Challenge 7\n",
    "\n",
    "Achmad Dhani\n",
    "\n",
    "HCK-009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X76Oe_xDhgRh"
   },
   "source": [
    "# Importing Libraries and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dlBJLDJFhiLF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# preprocess\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "# model\n",
    "from tensorflow.keras.models import load_model\n",
    "# etc\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHKF4Mjs12z1",
    "outputId": "9d9cfb71-4222-4470-dcd4-e4bd47965b3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uP8L3K_93zwT"
   },
   "outputs": [],
   "source": [
    "stopword_list= joblib.load('stopword_list.joblib')\n",
    "model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8stqn90A1UaF"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "m78tMEZE1WCQ"
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    tokens = word_tokenize(text) # tokenize\n",
    "    filtered_words = [word for word in tokens if word.lower() not in stopword_list]\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in filtered_words]\n",
    "    lemmatized_clean = [word.translate(str.maketrans('', '', string.punctuation)) for word in lemmatized_words]\n",
    "    return ' '.join(lemmatized_clean)\n",
    "\n",
    "def prediction(model, X):\n",
    "  y_pred = model.predict(X)\n",
    "  predictions = np.argmax(y_pred, axis=1)\n",
    "  for index, val in enumerate(predictions):\n",
    "    if val == 0:\n",
    "      print(f\"Text {index} indicates the person is feeling FEAR\")\n",
    "    elif val == 1:\n",
    "      print(f\"Text {index} indicates the person is feeling ANGER\")\n",
    "    else:\n",
    "      print(f\"Text {index} indicates the person is feeling JOY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxX_HcSU15uJ"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QeHZZM2x16mP"
   },
   "outputs": [],
   "source": [
    "# input\n",
    "input1= 'I feel so happy, listening to my favorite music'\n",
    "input2= 'Exam is tommorow, im so nervous'\n",
    "input3= 'Devin is mad right now'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GUqlQq-B3Z_j"
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "x = preprocess_text(input1)\n",
    "y = preprocess_text(input2)\n",
    "z = preprocess_text(input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zz4w2-Dg5Bgw",
    "outputId": "87187c40-256b-40b4-f8cd-21cf479a84d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Text 0 indicates the person is feeling JOY\n",
      "Text 1 indicates the person is feeling FEAR\n",
      "Text 2 indicates the person is feeling ANGER\n"
     ]
    }
   ],
   "source": [
    "# predicting\n",
    "prediction(model, [x,y,z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the model works"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
